## 特征提取 ##
在机器学习中，特征提取常常是一个巨大的工程，常见的特征提取有数字型和文本型最为常见。

### 数字型特征提取  ##

数字性特征可以直接用作特征，但是对于一个多维的特征，如果其取值范围特别大，则很很容易导致其他特征对结果的影响被忽略，这个时候我们需要对数字型特征进行预处理。常见的数字型特征与处理的方式有以下几种：

1. 标准化

将特征数据的分布调整成标准正太分布，也叫高斯分布，也就是使得数据的均值维0，方差为1.
标准化的原因在于如果有些特征的方差过大，则会主导目标函数从而使参数估计器无法正确地去学习其他特征。

经过标准化后的数据具有两个特征：去均值的中心化（均值变为0）和方差的规模化（方差变为1）

	from sklearn import preprocessing
	import numpy as np

	# 创建一组特征数据，每一行表示一个样本，每一列表示一个特征
	x = np.array([[1., -1., 2.],
              	[2., 0., 0.],
              	[0., 1., -1.]])
	# 将每一列特征标准化为标准正太分布，注意，标准化是针对每一列而言的
	x_scale = preprocessing.scale(x)
	x_scale
		array([[ 0.        , -1.22474487,  1.33630621],
       		[ 1.22474487,  0.        , -0.26726124],
       		[-1.22474487,  1.22474487, -1.06904497]])
	# 可以查看标准化后的数据的均值与方差，已经变成0,1了
	x_scale.mean(axis=0)
		array([ 0.,  0.,  0.])
	# axis=1表示对每一行去做这个操作，axis=0表示对每一列做相同的这个操作
	x_scale.mean(axis=1)
		array([ 0.03718711,  0.31916121, -0.35634832])
	# 同理，看一下标准差
	x_scale.std(axis=0)
		array([ 1.,  1.,  1.])

preprocessing这个模块还提供了一个实用类StandardScaler，当之前的训练集做了标准化操作之后，将相同的转换操作应用到测试训练集中。
这样当之后有新的数据进来的时候也可以直接调用该类，则不用将所有数据放在一起重新计算一次。

	# 调用fit方法，根据已有的训练数据创建一个标准化的转换器
	scaler = preprocessing.StandardScaler().fit(x)
	scaler
		StandardScaler(copy=True, with_mean=True, with_std=True)

	# 使用上面这个转换器去转换训练数据x,调用transform方法
	scaler.transform(x)
		array([[ 0.        , -1.22474487,  1.33630621],
		       [ 1.22474487,  0.        , -0.26726124],
		       [-1.22474487,  1.22474487, -1.06904497]])
	# 好了，比如现在又来了一组新的样本，也想得到相同的转换
	new_x = [[-1., 1., 0.]]
	scaler.transform(new_x)
		array([[-2.44948974,  1.22474487, -0.26726124]])

StandardScaler()中可以传入两个参数：with_mean,with_std.这两个都是布尔型的参数，默认情况下都是true,但也可以自定义成false.即不要均值中心化或者不要方差规模化为1.

2. 正则化
3. 归一化

