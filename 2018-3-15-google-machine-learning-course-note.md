---
layout: default
---


# Google机器学习教程笔记（一）#


许久没写过笔记，最近在跟进Google刚刚开源的自家使用Tensorflow的ML学习教程，将ML从头捋一捋。


----------
## 训练和损失 ###

训练模型表示通过有标签样本来学习（确定）所有权重和偏差的理想值。在监督式学习中，机器学习算法通过以下方式构建模型：检查多个样本并尝试找出可最大限度地减少损失的模型；这一过程称为经验风险最小化。

损失是对糟糕预测的惩罚。也就是说，损失是一个数值，表示对于单个样本而言模型预测的准确程度。如果模型的预测完全准确，则损失为零，否则损失会较大。训练模型的目标是从所有样本中找到一组平均损失“较小”的权重和偏差。例如，图 3 左侧显示的是损失较大的模型，右侧显示的是损失较小的模型。关于此图，请注意以下几点：



- 红色箭头表示损失。


- 蓝线表示预测。

![](https://i.imgur.com/lfuVQpE.png)

接下来是介绍几种常见的损失函数

1.平方损失

单个样本的平方损失如下：

	= the square of the difference between the label and the prediction
  	= (observation - prediction(x))2
  	= (y - y')2

2.均方误差（MSE）

指的是每个样本的平均平方损失。要计算 MSE，请求出各个样本的所有平方损失之和，然后除以样本数量：

![](https://i.imgur.com/5cge4K9.png)

![](https://i.imgur.com/wsPastB.png)

## 降低LOSS ##
现在我们可以得到训练好的模型，那么我们如何可以降低模型的训练损失，从而得到一个更好的模型？

### 梯度下降 ###

梯度下降法是我们现在使用最多的机器学习降低模型损失的方法，相较于迭代方法（仅是胡乱猜测权值），梯度下降则更有目的性，更快可以获得最优的模型。

假设我们有时间和计算资源来计算 w1 的所有可能值的损失。对于我们一直在研究的回归问题，所产生的损失与 w1 的图形始终是凸形。换言之，图形始终是碗状图，如下所示：

![](https://i.imgur.com/v54oS4u.png)

凸形问题只有一个最低点；即只存在一个斜率正好为 0 的位置。这个最小值就是损失函数收敛之处。

通过计算整个数据集中 w1 每个可能值的损失函数来找到收敛点这种方法效率太低。我们来研究一种更好的机制，这种机制在机器学习领域非常热门，称为梯度下降法。

梯度下降法的第一个阶段是为 w1 选择一个起始值（起点）。起点并不重要；因此很多算法就直接将 w1 设为 0 或随机选择一个值。下图显示的是我们选择了一个稍大于 0 的起点：

![](https://i.imgur.com/PYmXsUS.png)

然后，梯度下降法算法会计算损失曲线在起点处的梯度。简而言之，梯度是偏导数的矢量；它可以让您了解哪个方向距离目标“更近”或“更远”。请注意，损失相对于单个权重的梯度（如图 3 所示）就等于导数。

请注意，梯度是一个矢量，因此具有以下两个特征：

- 方向

- 大小

梯度始终指向损失函数中增长最为迅猛的方向。梯度下降法算法会沿着负梯度的方向走一步，以便尽快降低损失。

![](https://i.imgur.com/B0wSUKw.png)

为了确定损失函数曲线上的下一个点，梯度下降法算法会将梯度大小的一部分与起点相加，如下图所示：

![](https://i.imgur.com/TTrPW5C.png)

然后，梯度下降法会重复此过程，逐渐接近最低点。

这个就是梯度下降获得最优模型的原理。

#### 偏导数和梯度 ####

关于梯度下降，其中最重要的是偏导数和梯度的概念。从数学上解释：

![](https://i.imgur.com/MkIDlzF.png)

![](https://i.imgur.com/q6XlJq9.png)

![](https://i.imgur.com/tBHlRYu.png)

![](https://i.imgur.com/CwFJ5zf.png)

### 学习率（learning rate） ###

正如之前所述，梯度矢量具有方向和大小。梯度下降法算法用梯度乘以一个称为学习速率（有时也称为步长）的标量，以确定下一个点的位置。例如，如果梯度大小为 2.5，学习速率为 0.01，则梯度下降法算法会选择距离前一个点 0.025 的位置作为下一个点。

如果选择的学习率太小，则会花费太长的学习时间：

![](https://i.imgur.com/71RgQYl.png)

相反，如果指定的学习速率过大，下一个点将永远在 U 形曲线的底部随意弹跳，就好像量子力学实验出现了严重错误一样：

![](https://i.imgur.com/rzX0M8q.png)

![](https://i.imgur.com/vTdg4Et.png)

### 随机梯度下降 ###

在梯度下降法中，批量指的是用于在单次迭代中计算梯度的样本总数。到目前为止，我们一直假定批量是指整个数据集。就 Google 的规模而言，数据集通常包含数十亿甚至数千亿个样本。此外，Google 数据集通常包含海量特征。因此，一个批量可能相当巨大。如果是超大批量，则单次迭代就可能要花费很长时间进行计算。

包含随机抽样样本的大型数据集可能包含冗余数据。实际上，批量大小越大，出现冗余的可能性就越高。一些冗余可能有助于消除杂乱的梯度，但超大批量所具备的预测价值往往并不比大型批量高。

如果我们可以通过更少的计算量得出正确的平均梯度，会怎么样？通过从我们的数据集中随机选择样本，我们可以通过小得多的数据集估算（尽管过程非常杂乱）出较大的平均值。 随机梯度下降法 (SGD) 将这种想法运用到极致，它每次迭代只使用一个样本（批量大小为 1）。如果进行足够的迭代，SGD 也可以发挥作用，但过程会非常杂乱。“随机”这一术语表示构成各个批量的一个样本都是随机选择的。

小批量随机梯度下降法（小批量 SGD）是介于全批量迭代与 SGD 之间的折衷方案。小批量通常包含 10-1000 个随机选择的样本。小批量 SGD 可以减少 SGD 中的杂乱样本数量，但仍然比全批量更高效。

## 数据泛化：过拟合的风险 ##

本单元将重点介绍泛化。为了让您直观地理解这一概念，我们将展示 3 张图。假设这些图中的每个点代表一棵树在森林中的位置。图中的两种颜色分别代表以下含义：

- 蓝点代表生病的树。


- 橙点代表健康的树。

![](https://i.imgur.com/E8nvVQr.png)

然后再看看图 2，它显示某种机器学习模型如何将生病的树与健康的树区分开。请注意，该模型产生的损失非常低。

![](https://i.imgur.com/HClyrNG.png)

图 3 显示我们向该模型中添加了新数据后所发生的情况。结果表明，该模型在处理新数据方面表现非常糟糕。请注意，该模型对大部分新数据的分类都不正确。

![](https://i.imgur.com/h19YRlu.png)

图 2 和图 3 所示的模型过拟合了训练数据的特性。过拟合模型在训练过程中产生的损失很低，但在预测新数据方面的表现却非常糟糕。如果某个模型在拟合当前样本方面表现良好，那么我们如何相信该模型会对新数据做出良好的预测呢？过拟合是由于模型的复杂程度超出所需程度而造成的。机器学习的基本冲突是适当拟合我们的数据，但也要尽可能简单地拟合数据。

机器学习的目标是对从真实概率分布（已隐藏）中抽取的新数据做出良好预测。遗憾的是，模型无法查看整体情况；模型只能从训练数据集中取样。如果某个模型在拟合当前样本方面表现良好，那么如何相信该模型也会对从未见过的样本做出良好预测呢？

### 机器学习模型越简单，良好的实证结果就越有可能不仅仅基于样本的特性。

以下三项基本假设阐明了泛化：



- 我们从分布中随机抽取独立同分布 (i.i.d) 的样本。换言之，样本之间不会互相影响。（另一种解释：i.i.d. 是表示变量随机性的一种方式）。


- 分布是平稳的；即分布在数据集内不会发生变化。


- 我们从同一分布的数据划分中抽取样本。

如果违背了上述三项基本假设中的任何一项，那么我们就必须密切注意指标。

总体来说：

- 如果某个模型尝试紧密拟合训练数据，但却不能很好地泛化到新数据，就会发生过拟合。


- 如果不符合监督式机器学习的关键假设，那么我们将失去对新数据进行预测这项能力的重要理论保证。


## 数据集划分 ##

一般而言，我们会将数据集划分为两个子集的概念：

- 训练集：用于训练模型的子集
- 测试集 - 用于测试训练后模型的子集

此时，要确保测试集满足以下两个条件：

- 规模足够大，可产生具有统计意义的结果。
- 能代表整个数据集。换言之，挑选的测试集的特征应该与训练集的特征相同。

当采用上述划分的时候，工作流程如下：

![](https://i.imgur.com/m13qbSf.png)

在图中，“调整模型”指的是调整您可以想到的关于模型的任何方面，从更改学习速率、添加或移除特征，到从头开始设计全新模型。该工作流程结束时，您可以选择在测试集上获得最佳效果的模型。

将数据集划分为两个子集是个不错的想法，但不是万能良方。通过将数据集划分为三个子集（训练集、验证集、测试集），可以大幅降低过拟合的发生几率。

使用验证集评估训练集的效果。然后，在模型“通过”验证集之后，使用测试集再次检查评估结果。下图展示了这一新工作流程：

![](https://i.imgur.com/IBcjRkL.png)

在这一经过改进的工作流程中：



1. 选择在验证集上获得最佳效果的模型。
2. 使用测试集再次检查该模型。

该工作流程之所以更好，原因在于它暴露给测试集的信息更少。

注意：

不断使用测试集和验证集会使其逐渐失去效果。也就是说，使用相同数据来决定超参数设置或其他模型改进的次数越多，对于这些结果能够真正泛化到未见过的新数据的信心就越低。请注意，验证集的失效速度通常比测试集缓慢。

如果可能的话，建议收集更多数据来“刷新”测试集和验证集。重新开始是一种很好的重置方式。